# Autoencoder training image with PyTorch, MLflow, and data connectors
#
# Build:
#   docker build -t dfp-autoencoder-train:v8 -f tools/docker/Dockerfile.autoencoder_train .
#
# For Kind clusters:
#   kind load docker-image dfp-autoencoder-train:v8 --name dfp-kind
#
# Note: Using Python 3.11 for PySpark 3.5.x compatibility (3.12 has issues with PySpark)

FROM python:3.11-slim

# Install system dependencies including Java for PySpark
# Using Java 21 (available in Debian Trixie) - works with PySpark 3.5.x in practice
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    openjdk-21-jre-headless \
    && rm -rf /var/lib/apt/lists/*

# Set JAVA_HOME dynamically based on architecture
# Creates a symlink so JAVA_HOME works regardless of arch (arm64/amd64)
RUN ARCH=$(dpkg --print-architecture) && \
    ln -sf /usr/lib/jvm/java-21-openjdk-${ARCH} /usr/lib/jvm/java-21-openjdk
ENV JAVA_HOME=/usr/lib/jvm/java-21-openjdk
ENV PATH="${JAVA_HOME}/bin:${PATH}"

# Install uv for fast, reproducible Python package installation
COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

# Create app directory
WORKDIR /app

# Install Python dependencies using uv
# Note: Using CPU-only torch for smaller image size in Kind clusters
# feast[spark] provides Iceberg/Spark offline store integration
RUN uv pip install --system --no-cache \
    "torch>=2.5.0,<2.6" \
    "lightning>=2.0" \
    "tensorboard>=2.0" \
    "mlflow>=2.10,<2.15" \
    "pyspark>=3.5.0,<4.0" \
    "pandas>=2.0" \
    "numpy>=1.24" \
    "pyarrow>=14.0" \
    "requests>=2.31" \
    "psutil>=5.9" \
    "pyyaml>=6.0" \
    "boto3>=1.34" \
    "sqlalchemy>=2.0" \
    "feast[spark]>=0.32" \
    "kfp>=2.7,<3"

# Default command (KFP will inject actual training code at runtime)
CMD ["python", "-c", "print('Autoencoder training image ready')"]
