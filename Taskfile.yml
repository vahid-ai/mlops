version: "3"

vars:
  CLUSTER_NAME: '{{.CLUSTER_NAME | default "dfp-kind"}}'
  KIND_CONFIG: '{{.KIND_CONFIG | default "./infra/k8s/kind/kind-config.yaml"}}'
  KUSTOMIZE_DIR: '{{.KUSTOMIZE_DIR | default "./infra/k8s/kind/manifests"}}'
  NAMESPACE: '{{.NAMESPACE | default "dfp"}}'
  PORT_FORWARD: '{{.PORT_FORWARD | default "1"}}'

tasks:
  tools:
    desc: Install pinned tooling via mise
    cmds:
      - mise install

  up:
    desc: Create kind cluster and deploy local services (use up:full to include Kubeflow Pipelines)
    cmds:
      - task: kind:up
      - task: spark-operator:install
      - task: spark-image

  up:full:
    desc: Create kind cluster with all services including Kubeflow Pipelines
    cmds:
      - task: kind:up
      - task: spark-operator:install
      - task: kubeflow:install
      - task: spark-image
      - task: kfp-training-image

  down:
    desc: Delete kind cluster
    cmds:
      - task: kind:down

  status:
    desc: Show kind cluster and namespace status
    cmds:
      - task: kind:status

  logs:
    desc: Tail logs for a deployment (APP=minio|redis|lakefs|mlflow|lakefs-postgres)
    vars:
      APP: '{{.APP | default ""}}'
    cmds:
      - task: kind:logs
        vars:
          APP: "{{.APP}}"

  port-forward:
    desc: Port-forward local service endpoints to localhost
    cmds:
      - bash ./tools/scripts/kind_portforward.sh start

  port-forward:stop:
    desc: Stop port-forwards started by this repo
    cmds:
      - bash ./tools/scripts/kind_portforward.sh stop

  port-forward:status:
    desc: Show port-forward status
    cmds:
      - bash ./tools/scripts/kind_portforward.sh status

  kind:up:
    desc: Bootstrap kind + apply kustomize overlay
    env:
      CLUSTER_NAME: "{{.CLUSTER_NAME}}"
      NAMESPACE: "{{.NAMESPACE}}"
      KIND_CONFIG: "{{.KIND_CONFIG}}"
      KUSTOMIZE_DIR: "{{.KUSTOMIZE_DIR}}"
      PORT_FORWARD: "{{.PORT_FORWARD}}"
    cmds:
      - bash ./tools/scripts/kind_bootstrap.sh

  kind:down:
    desc: Delete kind cluster
    cmds:
      - kind delete cluster --name "{{.CLUSTER_NAME}}"

  kind:status:
    desc: Show deployments/pods/services in the dfp namespace
    cmds:
      - |
          if ! kind get clusters | grep -qx "{{.CLUSTER_NAME}}"; then
            echo "kind cluster '{{.CLUSTER_NAME}}' not found"
            exit 0
          fi
      - kubectl -n "{{.NAMESPACE}}" get deploy,po,svc

  kind:logs:
    desc: Tail logs for APP (deployment name)
    vars:
      APP: '{{.APP | default ""}}'
    cmds:
      - |
          if [ -z "{{.APP}}" ]; then
            echo "Set APP=... (minio|redis|lakefs|mlflow|lakefs-postgres)"
            kubectl -n "{{.NAMESPACE}}" get deployments
            exit 0
          fi
      - kubectl -n "{{.NAMESPACE}}" logs deployment/"{{.APP}}" -f --tail=200

  spark-image:build:
    desc: Build the dfp-spark Docker image
    vars:
      SPARK_IMAGE: '{{.SPARK_IMAGE | default "dfp-spark:latest"}}'
    cmds:
      - docker build -t "{{.SPARK_IMAGE}}" -f tools/docker/Dockerfile.spark .

  spark-image:load:
    desc: Load dfp-spark image into kind cluster
    vars:
      SPARK_IMAGE: '{{.SPARK_IMAGE | default "dfp-spark:latest"}}'
    cmds:
      - kind load docker-image "{{.SPARK_IMAGE}}" --name "{{.CLUSTER_NAME}}"

  spark-image:
    desc: Build and load dfp-spark image into kind
    cmds:
      - task: spark-image:build
      - task: spark-image:load

  kfp-training-image:build:
    desc: Build the dfp-kfp-training Docker image (for KFP autoencoder training)
    vars:
      KFP_TRAINING_IMAGE: '{{.KFP_TRAINING_IMAGE | default "dfp-kfp-training:latest"}}'
    cmds:
      - docker build -t "{{.KFP_TRAINING_IMAGE}}" -f tools/docker/Dockerfile.kfp_training .

  kfp-training-image:load:
    desc: Load dfp-kfp-training image into kind cluster
    vars:
      KFP_TRAINING_IMAGE: '{{.KFP_TRAINING_IMAGE | default "dfp-kfp-training:latest"}}'
    cmds:
      - kind load docker-image "{{.KFP_TRAINING_IMAGE}}" --name "{{.CLUSTER_NAME}}"

  kfp-training-image:
    desc: Build and load dfp-kfp-training image into kind (for KFP autoencoder training)
    cmds:
      - task: kfp-training-image:build
      - task: kfp-training-image:load

  spark-operator:install:
    desc: Install Spark Operator via Helm
    vars:
      SPARK_OPERATOR_NAMESPACE: '{{.SPARK_OPERATOR_NAMESPACE | default "spark-operator"}}'
      SPARK_OPERATOR_VALUES: '{{.SPARK_OPERATOR_VALUES | default "./infra/k8s/spark-operator/values.yaml"}}'
    cmds:
      - |
          if ! command -v helm >/dev/null 2>&1; then
            echo "helm is required. Install from https://helm.sh/docs/intro/install/" >&2
            exit 1
          fi
      - helm repo add spark-operator https://kubeflow.github.io/spark-operator 2>/dev/null || true
      - helm repo update spark-operator
      - |
          if helm status spark-operator -n "{{.SPARK_OPERATOR_NAMESPACE}}" >/dev/null 2>&1; then
            echo "Spark Operator already installed, upgrading..."
            helm upgrade spark-operator spark-operator/spark-operator \
              --namespace "{{.SPARK_OPERATOR_NAMESPACE}}" \
              --values "{{.SPARK_OPERATOR_VALUES}}"
          else
            echo "Installing Spark Operator..."
            helm install spark-operator spark-operator/spark-operator \
              --namespace "{{.SPARK_OPERATOR_NAMESPACE}}" \
              --create-namespace \
              --values "{{.SPARK_OPERATOR_VALUES}}"
          fi
      - kubectl -n "{{.SPARK_OPERATOR_NAMESPACE}}" rollout status deployment/spark-operator-controller --timeout=120s
      - echo "Spark Operator installed successfully"

  spark-operator:uninstall:
    desc: Uninstall Spark Operator
    vars:
      SPARK_OPERATOR_NAMESPACE: '{{.SPARK_OPERATOR_NAMESPACE | default "spark-operator"}}'
    cmds:
      - helm uninstall spark-operator -n "{{.SPARK_OPERATOR_NAMESPACE}}" || true
      - kubectl delete namespace "{{.SPARK_OPERATOR_NAMESPACE}}" --ignore-not-found

  spark-operator:status:
    desc: Show Spark Operator status
    vars:
      SPARK_OPERATOR_NAMESPACE: '{{.SPARK_OPERATOR_NAMESPACE | default "spark-operator"}}'
    cmds:
      - |
          if helm status spark-operator -n "{{.SPARK_OPERATOR_NAMESPACE}}" >/dev/null 2>&1; then
            echo "Spark Operator is installed"
            kubectl -n "{{.SPARK_OPERATOR_NAMESPACE}}" get pods
          else
            echo "Spark Operator is not installed"
          fi
      - echo ""
      - echo "SparkApplications in {{.NAMESPACE}}:"
      - kubectl -n "{{.NAMESPACE}}" get sparkapplications 2>/dev/null || echo "  (none or CRD not installed)"

  kubeflow:install:
    desc: Install Kubeflow Pipelines standalone via kustomize
    vars:
      KFP_NAMESPACE: '{{.KFP_NAMESPACE | default "kubeflow"}}'
      KFP_VERSION: '{{.KFP_VERSION | default "2.15.0"}}'
    cmds:
      - |
          if ! command -v kubectl >/dev/null 2>&1; then
            echo "kubectl is required. Install from https://kubernetes.io/docs/tasks/tools/" >&2
            exit 1
          fi
      - kubectl create namespace "{{.KFP_NAMESPACE}}" --dry-run=client -o yaml | kubectl apply -f -
      - |
          echo "Installing Kubeflow Pipelines v{{.KFP_VERSION}}..."
          kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref={{.KFP_VERSION}}"
          kubectl wait --for condition=established --timeout=60s crd/applications.app.k8s.io || true
          kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/env/platform-agnostic-emissary?ref={{.KFP_VERSION}}"
      - |
          echo "Waiting for KFP deployments to be ready..."
          kubectl -n "{{.KFP_NAMESPACE}}" rollout status deployment/ml-pipeline --timeout=300s || true
          kubectl -n "{{.KFP_NAMESPACE}}" rollout status deployment/ml-pipeline-ui --timeout=300s || true
      - echo "Kubeflow Pipelines installed successfully in namespace {{.KFP_NAMESPACE}}"
      - 'echo "Access the UI via: kubectl port-forward -n {{.KFP_NAMESPACE}} svc/ml-pipeline-ui 8080:80"'

  kubeflow:uninstall:
    desc: Uninstall Kubeflow Pipelines
    vars:
      KFP_NAMESPACE: '{{.KFP_NAMESPACE | default "kubeflow"}}'
      KFP_VERSION: '{{.KFP_VERSION | default "2.15.0"}}'
    cmds:
      - |
          echo "Uninstalling Kubeflow Pipelines..."
          kubectl delete -k "github.com/kubeflow/pipelines/manifests/kustomize/env/platform-agnostic-emissary?ref={{.KFP_VERSION}}" --ignore-not-found || true
          kubectl delete -k "github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref={{.KFP_VERSION}}" --ignore-not-found || true
      - kubectl delete namespace "{{.KFP_NAMESPACE}}" --ignore-not-found
      - echo "Kubeflow Pipelines uninstalled"

  kubeflow:status:
    desc: Show Kubeflow Pipelines status
    vars:
      KFP_NAMESPACE: '{{.KFP_NAMESPACE | default "kubeflow"}}'
    cmds:
      - |
          if kubectl get namespace "{{.KFP_NAMESPACE}}" >/dev/null 2>&1; then
            echo "Kubeflow Pipelines namespace exists"
            kubectl -n "{{.KFP_NAMESPACE}}" get pods
          else
            echo "Kubeflow Pipelines namespace '{{.KFP_NAMESPACE}}' not found"
          fi
      - echo ""
      - 'echo "KFP API endpoint:"'
      - kubectl -n "{{.KFP_NAMESPACE}}" get svc ml-pipeline -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}' 2>/dev/null && echo "" || echo "  (not available)"

  kubeflow:port-forward:
    desc: Port-forward Kubeflow Pipelines UI to localhost:8080
    vars:
      KFP_NAMESPACE: '{{.KFP_NAMESPACE | default "kubeflow"}}'
    cmds:
      - 'echo "Forwarding KFP UI to http://localhost:8080 (press Ctrl+C to stop)"'
      - 'kubectl port-forward -n "{{.KFP_NAMESPACE}}" svc/ml-pipeline-ui 8080:80'

  spark-ui:
    desc: Port-forward Spark UI to localhost:4040 (requires running SparkApplication)
    vars:
      SPARK_APP: '{{.SPARK_APP | default ""}}'
    cmds:
      - |
          if [ -z "{{.SPARK_APP}}" ]; then
            echo "Looking for running SparkApplications in {{.NAMESPACE}}..."
            kubectl -n "{{.NAMESPACE}}" get sparkapplications -o custom-columns=NAME:.metadata.name,STATE:.status.applicationState.state 2>/dev/null || echo "  (none found)"
            echo ""
            echo "Usage: task spark-ui SPARK_APP=<app-name>"
            echo "Or port-forward directly to the driver pod:"
            echo "  kubectl -n {{.NAMESPACE}} port-forward <driver-pod> 4040:4040"
          else
            SVC_NAME="{{.SPARK_APP}}-ui-svc"
            echo "Forwarding Spark UI to http://localhost:4040 (press Ctrl+C to stop)"
            echo "Service: ${SVC_NAME}"
            kubectl -n "{{.NAMESPACE}}" port-forward "svc/${SVC_NAME}" 4040:4040
          fi

  spark-app:list:
    desc: List SparkApplications in the namespace
    cmds:
      - kubectl -n "{{.NAMESPACE}}" get sparkapplications -o custom-columns=NAME:.metadata.name,STATE:.status.applicationState.state,AGE:.metadata.creationTimestamp 2>/dev/null || echo "No SparkApplications found"

  spark-app:delete:
    desc: Delete a SparkApplication (SPARK_APP=<name> or ALL=1 to delete all)
    vars:
      SPARK_APP: '{{.SPARK_APP | default ""}}'
      ALL: '{{.ALL | default ""}}'
      FORCE: '{{.FORCE | default ""}}'
    cmds:
      - |
          if [ -n "{{.ALL}}" ]; then
            echo "Deleting all SparkApplications in {{.NAMESPACE}}..."
            kubectl -n "{{.NAMESPACE}}" delete sparkapplications --all
            exit 0
          fi
          if [ -z "{{.SPARK_APP}}" ]; then
            echo "SparkApplications in {{.NAMESPACE}}:"
            kubectl -n "{{.NAMESPACE}}" get sparkapplications -o custom-columns=NAME:.metadata.name,STATE:.status.applicationState.state 2>/dev/null || echo "  (none found)"
            echo ""
            echo "Usage:"
            echo "  task spark-app:delete SPARK_APP=<app-name>        # delete specific app"
            echo "  task spark-app:delete SPARK_APP=<app-name> FORCE=1  # force delete"
            echo "  task spark-app:delete ALL=1                       # delete all apps"
            exit 0
          fi
          if [ -n "{{.FORCE}}" ]; then
            echo "Force deleting SparkApplication {{.SPARK_APP}}..."
            kubectl -n "{{.NAMESPACE}}" delete sparkapplication "{{.SPARK_APP}}" --force --grace-period=0
          else
            echo "Deleting SparkApplication {{.SPARK_APP}}..."
            kubectl -n "{{.NAMESPACE}}" delete sparkapplication "{{.SPARK_APP}}"
          fi

  kfp:cleanup:
    desc: Delete old/stuck Kubeflow pipeline pods and workflows
    vars:
      KFP_NAMESPACE: '{{.KFP_NAMESPACE | default "kubeflow"}}'
      ALL: '{{.ALL | default ""}}'
    cmds:
      - |
          echo "=== Kubeflow Pipeline Pods ==="
          kubectl -n "{{.KFP_NAMESPACE}}" get pods -l 'workflows.argoproj.io/workflow' 2>/dev/null || echo "(none found)"
          echo ""
          
          if [ -z "{{.ALL}}" ]; then
            echo "Deleting completed/failed/pending pipeline pods..."
            kubectl -n "{{.KFP_NAMESPACE}}" delete pods --field-selector=status.phase=Succeeded -l 'workflows.argoproj.io/workflow' 2>/dev/null || true
            kubectl -n "{{.KFP_NAMESPACE}}" delete pods --field-selector=status.phase=Failed -l 'workflows.argoproj.io/workflow' 2>/dev/null || true
            kubectl -n "{{.KFP_NAMESPACE}}" delete pods --field-selector=status.phase=Pending -l 'workflows.argoproj.io/workflow' 2>/dev/null || true
          else
            echo "Deleting ALL pipeline pods..."
            kubectl -n "{{.KFP_NAMESPACE}}" delete pods -l 'workflows.argoproj.io/workflow' 2>/dev/null || true
          fi
          
          echo ""
          echo "Remaining pipeline pods:"
          kubectl -n "{{.KFP_NAMESPACE}}" get pods -l 'workflows.argoproj.io/workflow' 2>/dev/null || echo "(none)"

  kfp:workflows:list:
    desc: List Kubeflow pipeline workflows (Argo Workflows)
    vars:
      KFP_NAMESPACE: '{{.KFP_NAMESPACE | default "kubeflow"}}'
    cmds:
      - kubectl -n "{{.KFP_NAMESPACE}}" get workflows -o custom-columns='NAME:.metadata.name,STATUS:.status.phase,AGE:.metadata.creationTimestamp' 2>/dev/null || echo "No workflows found"

  kfp:workflows:delete:
    desc: Delete Kubeflow pipeline workflows (WORKFLOW=<name> or ALL=1)
    vars:
      KFP_NAMESPACE: '{{.KFP_NAMESPACE | default "kubeflow"}}'
      WORKFLOW: '{{.WORKFLOW | default ""}}'
      ALL: '{{.ALL | default ""}}'
    cmds:
      - |
          if [ -n "{{.ALL}}" ]; then
            echo "Deleting ALL workflows in {{.KFP_NAMESPACE}}..."
            kubectl -n "{{.KFP_NAMESPACE}}" delete workflows --all
            exit 0
          fi
          if [ -z "{{.WORKFLOW}}" ]; then
            echo "Workflows in {{.KFP_NAMESPACE}}:"
            kubectl -n "{{.KFP_NAMESPACE}}" get workflows -o custom-columns='NAME:.metadata.name,STATUS:.status.phase,AGE:.metadata.creationTimestamp' 2>/dev/null || echo "(none)"
            echo ""
            echo "Usage:"
            echo "  task kfp:workflows:delete WORKFLOW=<name>  # delete specific workflow"
            echo "  task kfp:workflows:delete ALL=1            # delete all workflows"
          else
            echo "Deleting workflow {{.WORKFLOW}}..."
            kubectl -n "{{.KFP_NAMESPACE}}" delete workflow "{{.WORKFLOW}}"
          fi
