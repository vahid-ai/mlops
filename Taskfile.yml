version: "3"

vars:
  CLUSTER_NAME: '{{.CLUSTER_NAME | default "dfp-kind"}}'
  KIND_CONFIG: '{{.KIND_CONFIG | default "./infra/k8s/kind/kind-config.yaml"}}'
  KUSTOMIZE_DIR: '{{.KUSTOMIZE_DIR | default "./infra/k8s/kind/manifests"}}'
  KFP_NAMESPACE: '{{.KFP_NAMESPACE | default "kubeflow"}}'
  KFP_HOST: '{{.KFP_HOST | default "http://localhost:8080/pipeline"}}'
  NAMESPACE: '{{.NAMESPACE | default "dfp"}}'
  PORT_FORWARD: '{{.PORT_FORWARD | default "1"}}'

tasks:
  tools:
    desc: Install pinned tooling via mise
    cmds:
      - mise install

  up:
    desc: Create kind cluster and deploy local services
    cmds:
      - task: kind:up
      - task: spark-operator:install
      - task: spark-image

  up:full:
    desc: Complete from-scratch setup - creates cluster, configures everything, and starts port-forwarding
    cmds:
      - |
        set -e
        echo "=== Starting complete MLOps platform setup ==="
        echo ""
        
        echo "Step 1/8: Tearing down any existing cluster..."
        kind delete cluster --name "{{.CLUSTER_NAME}}" || true
        task port-forward:stop || true
        sleep 2
        
        echo ""
        echo "Step 2/8: Creating kind cluster and deploying services..."
        task kind:up
        
        echo ""
        echo "Step 3/8: Installing Kubeflow Pipelines..."
        PIPELINE_VERSION=2.15.0
        kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref=$PIPELINE_VERSION"
        kubectl wait --for condition=established --timeout=60s crd/applications.app.k8s.io || true
        kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/env/platform-agnostic-emissary?ref=$PIPELINE_VERSION"
        
        echo ""
        echo "Step 4/8: Installing Spark Operator..."
        task spark-operator:install || {
          echo "Spark Operator install timed out, waiting for pods to be ready..."
          kubectl -n spark-operator wait --for=condition=ready pod -l app.kubernetes.io/name=spark-operator --timeout=300s || true
        }
        
        echo ""
        echo "Step 5/8: Building and loading Spark image..."
        task spark-image
        
        echo ""
        echo "Step 6/8: Waiting for all pods to be ready..."
        echo "Waiting for dfp namespace pods..."
        kubectl wait --for=condition=ready pod -l app=minio -n "{{.NAMESPACE}}" --timeout=180s || true
        kubectl wait --for=condition=ready pod -l app=lakefs -n "{{.NAMESPACE}}" --timeout=180s || true
        kubectl wait --for=condition=ready pod -l app=mlflow -n "{{.NAMESPACE}}" --timeout=180s || true
        kubectl wait --for=condition=ready pod -l app=redis -n "{{.NAMESPACE}}" --timeout=180s || true
        kubectl wait --for=condition=ready pod -l app=lakefs-postgres -n "{{.NAMESPACE}}" --timeout=180s || true
        
        echo "Waiting for kubeflow namespace pods (this may take a few minutes)..."
        # Wait for critical KFP pods with retries
        for i in 1 2 3; do
          kubectl wait --for=condition=ready pod -l app=ml-pipeline -n kubeflow --timeout=180s && break || sleep 10
        done
        kubectl wait --for=condition=ready pod -l app=ml-pipeline-ui -n kubeflow --timeout=180s || true
        kubectl wait --for=condition=ready pod -l app=seaweedfs -n kubeflow --timeout=180s || true
        kubectl wait --for=condition=ready pod -l app=mysql -n kubeflow --timeout=180s || true
        echo "Core KFP pods ready!"
        
        echo ""
        echo "Step 7/8: Generating LakeFS credentials..."
        task lakefs:keys
        
        echo ""
        echo "Step 8/8: Starting port-forwarding..."
        task port-forward:reset
        
        echo ""
        echo "====================================================="
        echo "  MLOps Platform Setup Complete!"
        echo "====================================================="
        echo ""
        echo "Services available at:"
        echo "  - Kubeflow Pipelines UI: http://localhost:8081"
        echo "  - Kubeflow Pipelines API: http://localhost:8080"
        echo "  - LakeFS:                 http://localhost:8000"
        echo "  - MinIO Console:          http://localhost:19001"
        echo "  - MinIO API:              http://localhost:19000"
        echo "  - MLflow:                 http://localhost:5050"
        echo "  - Redis:                  localhost:16379"
        echo ""
        echo "LakeFS credentials have been saved to .env"
        echo ""
        echo "You're ready to run Kubeflow pipelines!"


  down:
    desc: Delete kind cluster
    cmds:
      - task: kind:down

  status:
    desc: Show kind cluster and namespace status
    cmds:
      - task: kind:status

  logs:
    desc: Tail logs for a deployment (APP=minio|redis|lakefs|mlflow|lakefs-postgres)
    vars:
      APP: '{{.APP | default ""}}'
    cmds:
      - task: kind:logs
        vars:
          APP: "{{.APP}}"

  port-forward:
    desc: Port-forward local service endpoints to localhost
    cmds:
      - bash ./tools/scripts/kind_portforward.sh start

  port-forward:stop:
    desc: Stop port-forwards started by this repo
    cmds:
      - bash ./tools/scripts/kind_portforward.sh stop

  port-forward:status:
    desc: Show port-forward status
    cmds:
      - bash ./tools/scripts/kind_portforward.sh status

  port-forward:reset:
    desc: Kill all kubectl port-forwards and restart them fresh
    cmds:
      - pkill -f "kubectl.*port-forward" || true
      - sleep 0.5
      - bash ./tools/scripts/kind_portforward.sh start
  
  kubeflow:port-forward:
    desc: Port-forward Kubeflow Pipelines UI to localhost:8080
    vars:
      KFP_NAMESPACE: '{{.KFP_NAMESPACE | default "kubeflow"}}'
    cmds:
      - 'echo "Forwarding KFP UI to http://localhost:8080 (press Ctrl+C to stop)"'
      - 'kubectl port-forward -n "{{.KFP_NAMESPACE}}" svc/ml-pipeline-ui 8080:80'

  lakefs:keys:
    desc: Reset LakeFS and generate new credentials (updates .env file)
    cmds:
      - |
        set -e
        NAMESPACE="{{.NAMESPACE}}"
        
        echo "Resetting LakeFS to generate new credentials..."
        echo ""
        
        # Step 1: Reset the LakeFS postgres database
        echo "Step 1: Resetting LakeFS database..."
        kubectl exec -n "${NAMESPACE}" deployment/lakefs-postgres -- \
          psql -U lakefs -c "DROP SCHEMA public CASCADE; CREATE SCHEMA public;" 2>/dev/null || {
          echo "Warning: Could not reset database, continuing anyway..."
        }
        
        # Step 2: Restart LakeFS deployment to pick up fresh state
        echo "Step 2: Restarting LakeFS deployment..."
        kubectl rollout restart -n "${NAMESPACE}" deployment/lakefs
        kubectl rollout status -n "${NAMESPACE}" deployment/lakefs --timeout=120s
        
        # Give it a moment to initialize
        sleep 3
        
        # Step 3: Run setup to create new admin credentials
        echo "Step 3: Running LakeFS setup..."
        OUTPUT=$(kubectl exec -n "${NAMESPACE}" deployment/lakefs -- \
          lakefs setup --user-name admin 2>&1)
        
        echo "$OUTPUT" | tail -5
        
        # Parse credentials from output
        # Format is YAML: access_key_id: AKIAJ...  or  secret_access_key: ...
        ACCESS_KEY_ID=$(echo "$OUTPUT" | grep "access_key_id:" | awk '{print $2}' | head -1)
        SECRET_ACCESS_KEY=$(echo "$OUTPUT" | grep "secret_access_key:" | awk '{print $2}' | head -1)
        
        if [ -z "$ACCESS_KEY_ID" ] || [ -z "$SECRET_ACCESS_KEY" ]; then
          echo ""
          echo "Could not parse credentials from output."
          echo "Full output:"
          echo "$OUTPUT"
          echo ""
          echo "Please manually copy the access_key_id and secret_access_key to .env"
          exit 1
        fi
        
        echo ""
        echo "New credentials generated!"
        echo "  Access Key ID:     $ACCESS_KEY_ID"
        echo "  Secret Access Key: ${SECRET_ACCESS_KEY:0:10}..."
        
        # Update .env file
        if [ -f .env ]; then
          if grep -q "^LAKEFS_ACCESS_KEY_ID=" .env; then
            sed -i '' "s|^LAKEFS_ACCESS_KEY_ID=.*|LAKEFS_ACCESS_KEY_ID=$ACCESS_KEY_ID|" .env
          else
            echo "LAKEFS_ACCESS_KEY_ID=$ACCESS_KEY_ID" >> .env
          fi
          
          if grep -q "^LAKEFS_SECRET_ACCESS_KEY=" .env; then
            sed -i '' "s|^LAKEFS_SECRET_ACCESS_KEY=.*|LAKEFS_SECRET_ACCESS_KEY=$SECRET_ACCESS_KEY|" .env
          else
            echo "LAKEFS_SECRET_ACCESS_KEY=$SECRET_ACCESS_KEY" >> .env
          fi
          
          echo ""
          echo ".env file updated with new LakeFS credentials"
        else
          echo "LAKEFS_ACCESS_KEY_ID=$ACCESS_KEY_ID" > .env
          echo "LAKEFS_SECRET_ACCESS_KEY=$SECRET_ACCESS_KEY" >> .env
          echo ".env file created with LakeFS credentials"
        fi
        
        echo ""
        echo "Done! LakeFS has been reset with new credentials."
        echo ""
        echo "NOTE: All existing repositories and data in LakeFS have been deleted."
        echo "You may need to restart port-forwards: task port-forward:reset"

  kfp:clear:
    desc: Clear and delete all Kubeflow pipelines, runs, experiments, and kronodroid pods/services
    cmds:
      - uv run --with kfp,kubernetes tools/scripts/clear_kfp.py
    env:
      KFP_CLEAR_ALL_WORKFLOWS: "1"
      KFP_HOST: "{{.KFP_HOST}}"
      KFP_NAMESPACE: "{{.KFP_NAMESPACE}}"
      NAMESPACE: "{{.NAMESPACE}}"

  kfp:reset:
    desc: Delete all Argo workflow pods and resources in kubeflow and dfp namespaces
    vars:
      KFP_NAMESPACE: '{{.KFP_NAMESPACE | default "kubeflow"}}'
      NAMESPACE: '{{.NAMESPACE | default "dfp"}}'
    cmds:
      - |
        echo "Deleting workflow pods in {{.KFP_NAMESPACE}} namespace..."
        kubectl delete pods -n {{.KFP_NAMESPACE}} -l workflows.argoproj.io/workflow --ignore-not-found=true
        
        echo "Deleting completed pods in {{.KFP_NAMESPACE}} namespace..."
        kubectl delete pods -n {{.KFP_NAMESPACE}} --field-selector=status.phase=Succeeded --ignore-not-found=true
        
        echo "Deleting failed pods in {{.KFP_NAMESPACE}} namespace..."
        kubectl delete pods -n {{.KFP_NAMESPACE}} --field-selector=status.phase=Failed --ignore-not-found=true
        
        echo "Deleting all Argo workflows in {{.KFP_NAMESPACE}} namespace..."
        kubectl delete workflows -n {{.KFP_NAMESPACE}} --all --ignore-not-found=true
                
        echo "KFP reset complete."

  kind:up:
    desc: Bootstrap kind + apply kustomize overlay
    env:
      CLUSTER_NAME: "{{.CLUSTER_NAME}}"
      NAMESPACE: "{{.NAMESPACE}}"
      KIND_CONFIG: "{{.KIND_CONFIG}}"
      KUSTOMIZE_DIR: "{{.KUSTOMIZE_DIR}}"
      PORT_FORWARD: "{{.PORT_FORWARD}}"
    cmds:
      - bash ./tools/scripts/kind_bootstrap.sh

  kind:down:
    desc: Delete kind cluster
    cmds:
      - kind delete cluster --name "{{.CLUSTER_NAME}}"

  kind:status:
    desc: Show deployments/pods/services across all namespaces and service URLs
    vars:
      KFP_NAMESPACE: '{{.KFP_NAMESPACE | default "kubeflow"}}'
      SPARK_OPERATOR_NAMESPACE: '{{.SPARK_OPERATOR_NAMESPACE | default "spark-operator"}}'
    cmds:
      - |
          if ! kind get clusters | grep -qx "{{.CLUSTER_NAME}}"; then
            echo "kind cluster '{{.CLUSTER_NAME}}' not found"
            exit 0
          fi
          
          echo "=============================================="
          echo "  Namespace: {{.NAMESPACE}} (Core Services)"
          echo "=============================================="
          kubectl -n "{{.NAMESPACE}}" get deploy,po,svc
          
          echo ""
          echo "=============================================="
          echo "  Namespace: {{.KFP_NAMESPACE}} (Kubeflow Pipelines)"
          echo "=============================================="
          kubectl -n "{{.KFP_NAMESPACE}}" get deploy,po,svc 2>/dev/null || echo "  (namespace not found)"
          
          echo ""
          echo "=============================================="
          echo "  Namespace: {{.SPARK_OPERATOR_NAMESPACE}} (Spark Operator)"
          echo "=============================================="
          kubectl -n "{{.SPARK_OPERATOR_NAMESPACE}}" get deploy,po,svc 2>/dev/null || echo "  (namespace not found)"
          
          echo ""
          echo "=============================================="
          echo "  SparkApplications in {{.NAMESPACE}}"
          echo "=============================================="
          kubectl -n "{{.NAMESPACE}}" get sparkapplications 2>/dev/null || echo "  (none or CRD not installed)"
          
          echo ""
          echo "=============================================="
          echo "  Service Access URLs / Port-Forwards"
          echo "=============================================="
          echo ""
          echo "  DFP Namespace Services:"
          echo "    MinIO Console:          http://localhost:19001  (admin/minioadmin)"
          echo "    MinIO API:              http://localhost:19000"
          echo "    LakeFS:                 http://localhost:8000"
          echo "    MLflow:                 http://localhost:5050"
          echo "    Redis:                  localhost:16379"
          echo ""
          echo "  Kubeflow Namespace Services:"
          echo "    Kubeflow Pipelines UI:  http://localhost:8081"
          echo "    Kubeflow Pipelines API: http://localhost:8080"
          echo ""
          echo "  Run 'task port-forward:status' to check if port-forwards are active."
          echo ""

  kind:logs:
    desc: Tail logs for APP (deployment name)
    vars:
      APP: '{{.APP | default ""}}'
    cmds:
      - |
          if [ -z "{{.APP}}" ]; then
            echo "Set APP=... (minio|redis|lakefs|mlflow|lakefs-postgres)"
            kubectl -n "{{.NAMESPACE}}" get deployments
            exit 0
          fi
      - kubectl -n "{{.NAMESPACE}}" logs deployment/"{{.APP}}" -f --tail=200

  spark-image:build:
    desc: Build the dfp-spark Docker image
    vars:
      SPARK_IMAGE: '{{.SPARK_IMAGE | default "dfp-spark:latest"}}'
    cmds:
      - docker build -t "{{.SPARK_IMAGE}}" -f tools/docker/Dockerfile.spark .

  spark-image:load:
    desc: Load dfp-spark image into kind cluster
    vars:
      SPARK_IMAGE: '{{.SPARK_IMAGE | default "dfp-spark:latest"}}'
    cmds:
      - kind load docker-image "{{.SPARK_IMAGE}}" --name "{{.CLUSTER_NAME}}"

  spark-image:
    desc: Build and load dfp-spark image into kind
    cmds:
      - task: spark-image:build
      - task: spark-image:load

  spark-operator:install:
    desc: Install Spark Operator via Helm
    vars:
      SPARK_OPERATOR_NAMESPACE: '{{.SPARK_OPERATOR_NAMESPACE | default "spark-operator"}}'
      SPARK_OPERATOR_VALUES: '{{.SPARK_OPERATOR_VALUES | default "./infra/k8s/spark-operator/values.yaml"}}'
    cmds:
      - |
          if ! command -v helm >/dev/null 2>&1; then
            echo "helm is required. Install from https://helm.sh/docs/intro/install/" >&2
            exit 1
          fi
      - helm repo add spark-operator https://kubeflow.github.io/spark-operator 2>/dev/null || true
      - helm repo update spark-operator
      - |
          if helm status spark-operator -n "{{.SPARK_OPERATOR_NAMESPACE}}" >/dev/null 2>&1; then
            echo "Spark Operator already installed, upgrading..."
            helm upgrade spark-operator spark-operator/spark-operator \
              --namespace "{{.SPARK_OPERATOR_NAMESPACE}}" \
              --values "{{.SPARK_OPERATOR_VALUES}}"
          else
            echo "Installing Spark Operator..."
            helm install spark-operator spark-operator/spark-operator \
              --namespace "{{.SPARK_OPERATOR_NAMESPACE}}" \
              --create-namespace \
              --values "{{.SPARK_OPERATOR_VALUES}}"
          fi
      - kubectl -n "{{.SPARK_OPERATOR_NAMESPACE}}" rollout status deployment/spark-operator-controller --timeout=300s
      - echo "Spark Operator installed successfully"

  spark-operator:uninstall:
    desc: Uninstall Spark Operator
    vars:
      SPARK_OPERATOR_NAMESPACE: '{{.SPARK_OPERATOR_NAMESPACE | default "spark-operator"}}'
    cmds:
      - helm uninstall spark-operator -n "{{.SPARK_OPERATOR_NAMESPACE}}" || true
      - kubectl delete namespace "{{.SPARK_OPERATOR_NAMESPACE}}" --ignore-not-found

  spark-operator:status:
    desc: Show Spark Operator status
    vars:
      SPARK_OPERATOR_NAMESPACE: '{{.SPARK_OPERATOR_NAMESPACE | default "spark-operator"}}'
    cmds:
      - |
          if helm status spark-operator -n "{{.SPARK_OPERATOR_NAMESPACE}}" >/dev/null 2>&1; then
            echo "Spark Operator is installed"
            kubectl -n "{{.SPARK_OPERATOR_NAMESPACE}}" get pods
          else
            echo "Spark Operator is not installed"
          fi
      - echo ""
      - echo "SparkApplications in {{.NAMESPACE}}:"
      - kubectl -n "{{.NAMESPACE}}" get sparkapplications 2>/dev/null || echo "  (none or CRD not installed)"

  spark:logs:
    desc: Tail logs for the latest Spark job driver pod
    cmds:
      - |
        POD=$(kubectl get pods -n "{{.NAMESPACE}}" -l spark-role=driver --sort-by=.metadata.creationTimestamp -o name | tail -n 1)
        if [ -z "$POD" ]; then
          echo "No Spark driver pods found in namespace {{.NAMESPACE}}"
          exit 0
        fi
        POD_NAME=${POD#pod/}
        echo "Tailing logs for $POD_NAME..."
        kubectl logs -n "{{.NAMESPACE}}" "$POD" -f --tail=200
