# Spark Thrift Server Deployment
# Provides HiveServer2-compatible interface for dbt-spark
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-thrift-server
  namespace: dfp
  labels:
    app: spark-thrift-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-thrift-server
  template:
    metadata:
      labels:
        app: spark-thrift-server
    spec:
      containers:
        - name: spark-thrift
          image: bitnami/spark:3.5
          command:
            - /bin/bash
            - -c
            - |
              /opt/bitnami/spark/sbin/start-thrift-server.sh \
                --hiveconf hive.server2.thrift.port=10000 \
                --hiveconf hive.server2.thrift.bind.host=0.0.0.0 \
                --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
                --conf spark.sql.catalog.lakefs_catalog=org.apache.iceberg.spark.SparkCatalog \
                --conf spark.sql.catalog.lakefs_catalog.type=hadoop \
                --conf spark.sql.catalog.lakefs_catalog.warehouse=s3a://kronodroid/main/iceberg \
                --conf spark.hadoop.fs.s3a.endpoint=http://minio.dfp.svc.cluster.local:9000 \
                --conf spark.hadoop.fs.s3a.access.key=$AWS_ACCESS_KEY_ID \
                --conf spark.hadoop.fs.s3a.secret.key=$AWS_SECRET_ACCESS_KEY \
                --conf spark.hadoop.fs.s3a.path.style.access=true \
                --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \
                --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false \
                --conf spark.sql.iceberg.write.format.default=avro \
                --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 \
              && tail -f /opt/bitnami/spark/logs/*
          ports:
            - containerPort: 10000
              name: thrift
            - containerPort: 4040
              name: spark-ui
          env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: access-key
                  optional: true
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: secret-key
                  optional: true
            - name: SPARK_MODE
              value: "client"
          resources:
            requests:
              memory: "2Gi"
              cpu: "1"
            limits:
              memory: "4Gi"
              cpu: "2"
